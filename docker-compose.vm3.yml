version: "3.9"

# =============================================================================
# VM3 - PostgreSQL HA Cluster Node 3
# =============================================================================
# This compose file runs on VM3 and includes:
# - etcd node 3 (part of 3-node etcd cluster)
# - Patroni/Spilo PostgreSQL node 3
#
# IMPORTANT: Copy .env.vm3.example to .env.vm3 and configure before running
# =============================================================================

services:
  # ---------------------------------------------------------------------------
  # etcd - Distributed Key-Value Store for Patroni DCS
  # ---------------------------------------------------------------------------
  etcd3:
    image: quay.io/coreos/etcd:v3.5.11
    container_name: etcd3
    hostname: etcd3
    restart: unless-stopped
    network_mode: host # Use host network so etcd uses VM IP
    # ports not needed with network_mode: host
    environment:
      - ETCD_NAME=etcd3
      - ETCD_DATA_DIR=/etcd-data
      - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379
      - ETCD_ADVERTISE_CLIENT_URLS=http://${NODE3_IP:-127.0.0.1}:2379
      - ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380
      - ETCD_INITIAL_ADVERTISE_PEER_URLS=http://${NODE3_IP:-127.0.0.1}:2380
      - ETCD_INITIAL_CLUSTER=etcd1=http://${NODE1_IP:-127.0.0.1}:2380,etcd2=http://${NODE2_IP:-127.0.0.1}:2380,etcd3=http://${NODE3_IP:-127.0.0.1}:2380
      - ETCD_INITIAL_CLUSTER_TOKEN=etcd-patroni-cluster
      - ETCD_INITIAL_CLUSTER_STATE=new
      - ETCD_ENABLE_V2=true
      - ETCD_AUTO_COMPACTION_RETENTION=1
      - ETCD_AUTO_COMPACTION_MODE=periodic
      - ETCD_QUOTA_BACKEND_BYTES=8589934592
    volumes:
      - etcd3-data:/etcd-data
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # ---------------------------------------------------------------------------
  # Patroni - PostgreSQL HA Manager (using custom Supabase-Patroni image)
  # ---------------------------------------------------------------------------
  # Build: docker build -t supabase-patroni:latest -f docker/Dockerfile.supabase-patroni .
  # ---------------------------------------------------------------------------
  patroni3:
    image: ${PATRONI_IMAGE:-supabase-patroni:latest}
    container_name: patroni3
    hostname: patroni3
    restart: unless-stopped
    network_mode: host # Use host network so Patroni sees VM IP, not container IP
    # ports not needed with network_mode: host (container uses host ports directly)
    extra_hosts:
      - "patroni3:${NODE3_IP}" # Ensure hostname resolves to VM IP
    environment:
      # Disable cloud provider auto-detection (prevents 169.254.169.254 timeout)
      - SPILO_PROVIDER=local
      - AWS_REGION=
      - CALLBACK_SCRIPT=
      # Force IP address (bypasses hostname resolution in configure_spilo.py)
      - POD_IP=${NODE3_IP}

      # Spilo/Patroni settings
      - SCOPE=postgres-ha
      - PGVERSION=16
      - PGROOT=/home/postgres/pgdata/pgroot
      - PGDATA=/home/postgres/pgdata/pgroot/data
      - PGLOG=/home/postgres/pgdata/pgroot/pg_log

      # Patroni settings
      - PATRONI_SCOPE=postgres-ha
      - PATRONI_NAME=patroni3
      - PATRONI_RESTAPI_LISTEN=0.0.0.0:8008
      - PATRONI_RESTAPI_CONNECT_ADDRESS=${NODE3_IP}:8008
      - PATRONI_POSTGRESQL_LISTEN=0.0.0.0:5432
      - PATRONI_POSTGRESQL_CONNECT_ADDRESS=${NODE3_IP}:5432
      - PATRONI_POSTGRESQL_DATA_DIR=/home/postgres/pgdata/pgroot/data

      # etcd DCS configuration (must use actual VM IPs, not localhost)
      - PATRONI_ETCD3_HOSTS=${NODE1_IP}:2379,${NODE2_IP}:2379,${NODE3_IP}:2379

      # PostgreSQL superuser
      - PATRONI_SUPERUSER_USERNAME=postgres
      - PATRONI_SUPERUSER_PASSWORD=${POSTGRES_PASSWORD:-postgres}

      # Replication user
      - PATRONI_REPLICATION_USERNAME=replicator
      - PATRONI_REPLICATION_PASSWORD=${REPLICATION_PASSWORD:-replicator}

      # Additional settings
      - PATRONI_POSTGRESQL_PARAMETERS_MAX_CONNECTIONS=200
      - PATRONI_POSTGRESQL_PARAMETERS_SHARED_BUFFERS=256MB
      - PATRONI_POSTGRESQL_PARAMETERS_WAL_LEVEL=replica
      - PATRONI_POSTGRESQL_PARAMETERS_HOT_STANDBY=on
      - PATRONI_POSTGRESQL_PARAMETERS_MAX_WAL_SENDERS=10
      - PATRONI_POSTGRESQL_PARAMETERS_MAX_REPLICATION_SLOTS=10

      # Spilo-specific (includes post_init to run Supabase init script on bootstrap)
      # shared_preload_libraries includes pg_cron for scheduled jobs
      - SPILO_CONFIGURATION={"bootstrap":{"dcs":{"ttl":30,"loop_wait":10,"retry_timeout":10,"maximum_lag_on_failover":1048576,"postgresql":{"use_pg_rewind":true,"use_slots":true,"parameters":{"shared_preload_libraries":"pg_cron,pg_stat_statements"},"pg_hba":["local all all trust","host all all 0.0.0.0/0 md5","host all all ::0/0 md5","host replication replicator 0.0.0.0/0 md5"]}},"post_init":"/scripts/run-init.sh"}}
      - USE_WALG=false
      - ENABLE_WAL_PATH_COMPAT=true
    volumes:
      - patroni3-data:/home/postgres/pgdata
      - ./scripts:/scripts:ro
    depends_on:
      etcd3:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s

volumes:
  etcd3-data:
    driver: local
  patroni3-data:
    driver: local
